model_name="LLMMixer"

seq_len=192
e_layers=2
down_sampling_layers=3
down_sampling_window=2
learning_rate=0.0001
d_model=16
d_ff=32
train_epochs=20
patience=10
batch_size=128
learning_rate=0.001
pred_len=96

!python -u run.py \
  --task_name long_term_forecast \
  --is_training 1 \
  --root_path  /home/kowsher/tabllm \
  --data_path ETTh1.csv \
  --model_id ETTh1_$seq_len'_'96 \
  --model $model_name \
  --data ETTh1 \
  --features M \
  --seq_len $seq_len \
  --label_len 0 \
  --pred_len $pred_len \
  --e_layers $e_layers \
  --enc_in 7 \
  --c_out 7 \
  --des 'Exp' \
  --itr 1 \
  --d_model $d_model \
  --d_ff $d_ff \
  --learning_rate $learning_rate \
  --train_epochs $train_epochs \
  --patience $patience \
  --batch_size $batch_size \
  --learning_rate $learning_rate \
  --down_sampling_layers $down_sampling_layers \
  --down_sampling_method avg \
  --down_sampling_window $down_sampling_window
