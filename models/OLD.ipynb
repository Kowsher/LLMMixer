{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44d321-f062-4906-acaf-ec18df5ca0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers.Autoformer_EncDec import series_decomp\n",
    "from layers.Embed import DataEmbedding_wo_pos\n",
    "from layers.StandardNorm import Normalize\n",
    "import math\n",
    "import warnings\n",
    "from typing import Optional, Tuple, Union\n",
    "from layers.Transformer_EncDec1 import Encoder, EncoderLayer\n",
    "from layers.SelfAttention_Family1 import FullAttention, AttentionLayer\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, LayerNorm, MSELoss\n",
    "from torch.nn import functional as F\n",
    "from transformers import RobertaModel, RobertaConfig\n",
    "\n",
    "from transformers.file_utils import add_code_sample_docstrings, add_start_docstrings, add_start_docstrings_to_model_forward\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.utils import logging\n",
    "from transformers import AutoConfig, PreTrainedModel, AutoModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutput, Seq2SeqLMOutput\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "class TModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Normalization-Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(TModel, self).__init__()\n",
    "        self.seq_len = configs.pred_len\n",
    "        self.pred_len = configs.pred_len #+ configs.label_len\n",
    "        \n",
    "        # Use this line if you want to visualize the weights\n",
    "        # self.Linear.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "        self.channels = configs.c_out\n",
    "     \n",
    "        self.Linear1 = nn.Linear(self.seq_len, self.pred_len)\n",
    "        self.Linear = nn.Linear(self.pred_len, self.pred_len)\n",
    "        \n",
    "        #self.transform = TabularBertPredictionHeadTransform(config)\n",
    "        #print('decoder_dropout', decoder_dropout)\n",
    "        self.dropout = nn.Dropout(0.01) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "    #print(x.shape)\n",
    "        seq_last = x[:,-1:,:].detach()\n",
    "        x = x - seq_last\n",
    "        x = self.Linear1(x.permute(0,2,1)).permute(0,2,1)\n",
    "        x = self.dropout(x)\n",
    "        x = x + seq_last\n",
    "        \n",
    "        seq_last = x[:,-1:,:].detach()\n",
    "        x= x - seq_last\n",
    "        x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
    "        x = self.dropout(x)\n",
    "        x = x + seq_last\n",
    "        return x\n",
    "        \n",
    "class DFT_series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, top_k=5):\n",
    "        super(DFT_series_decomp, self).__init__()\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        xf = torch.fft.rfft(x)\n",
    "        freq = abs(xf)\n",
    "        freq[0] = 0\n",
    "        top_k_freq, top_list = torch.topk(freq, self.top_k)\n",
    "        xf[freq <= top_k_freq.min()] = 0\n",
    "        x_season = torch.fft.irfft(xf)\n",
    "        x_trend = x - x_season\n",
    "        return x_season, x_trend\n",
    "\n",
    "\n",
    "class MultiScaleSeasonMixing(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottom-up mixing season pattern\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(MultiScaleSeasonMixing, self).__init__()\n",
    "\n",
    "        self.down_sampling_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    torch.nn.Linear(\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),\n",
    "                    ),\n",
    "                    nn.GELU(),\n",
    "                    torch.nn.Linear(\n",
    "                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),\n",
    "                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),\n",
    "                    ),\n",
    "\n",
    "                )\n",
    "                for i in range(configs.down_sampling_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, season_list):\n",
    "\n",
    "        # mixing high->low\n",
    "        out_high = season_list[0]\n",
    "        out_low = season_list[1]\n",
    "        out_season_list = [out_high.permute(0, 2, 1)]\n",
    "\n",
    "        for i in range(len(season_list) - 1):\n",
    "            out_low_res = self.down_sampling_layers[i](out_high)\n",
    "            out_low = out_low + out_low_res\n",
    "            out_high = out_low\n",
    "            if i + 2 <= len(season_list) - 1:\n",
    "                out_low = season_list[i + 2]\n",
    "            out_season_list.append(out_high.permute(0, 2, 1))\n",
    "\n",
    "        return out_season_list\n",
    "\n",
    "\n",
    "class MultiScaleTrendMixing(nn.Module):\n",
    "    \"\"\"\n",
    "    Top-down mixing trend pattern\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(MultiScaleTrendMixing, self).__init__()\n",
    "\n",
    "        self.up_sampling_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    torch.nn.Linear(\n",
    "                        configs.seq_len // (configs.down_sampling_window ** (i + 1)),\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                    ),\n",
    "                    nn.GELU(),\n",
    "                    torch.nn.Linear(\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                    ),\n",
    "                )\n",
    "                for i in reversed(range(configs.down_sampling_layers))\n",
    "            ])\n",
    "\n",
    "    def forward(self, trend_list):\n",
    "\n",
    "        # mixing low->high\n",
    "        trend_list_reverse = trend_list.copy()\n",
    "        trend_list_reverse.reverse()\n",
    "        out_low = trend_list_reverse[0]\n",
    "        out_high = trend_list_reverse[1]\n",
    "        out_trend_list = [out_low.permute(0, 2, 1)]\n",
    "\n",
    "        for i in range(len(trend_list_reverse) - 1):\n",
    "            out_high_res = self.up_sampling_layers[i](out_low)\n",
    "            out_high = out_high + out_high_res\n",
    "            out_low = out_high\n",
    "            if i + 2 <= len(trend_list_reverse) - 1:\n",
    "                out_high = trend_list_reverse[i + 2]\n",
    "            out_trend_list.append(out_low.permute(0, 2, 1))\n",
    "\n",
    "        out_trend_list.reverse()\n",
    "        return out_trend_list\n",
    "\n",
    "\n",
    "class PastDecomposableMixing(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(PastDecomposableMixing, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.down_sampling_window = configs.down_sampling_window\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.channel_independence = configs.channel_independence\n",
    "\n",
    "        if configs.decomp_method == 'moving_avg':\n",
    "            self.decompsition = series_decomp(configs.moving_avg)\n",
    "        elif configs.decomp_method == \"dft_decomp\":\n",
    "            self.decompsition = DFT_series_decomp(configs.top_k)\n",
    "        else:\n",
    "            raise ValueError('decompsition is error')\n",
    "\n",
    "        if configs.channel_independence == 0:\n",
    "            self.cross_layer = nn.Sequential(\n",
    "                nn.Linear(in_features=configs.d_model, out_features=configs.d_ff),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(in_features=configs.d_ff, out_features=configs.d_model),\n",
    "            )\n",
    "\n",
    "        # Mixing season\n",
    "        self.mixing_multi_scale_season = MultiScaleSeasonMixing(configs)\n",
    "\n",
    "        # Mxing trend\n",
    "        self.mixing_multi_scale_trend = MultiScaleTrendMixing(configs)\n",
    "\n",
    "        self.out_cross_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=configs.d_model, out_features=configs.d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=configs.d_ff, out_features=configs.d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        length_list = []\n",
    "        for x in x_list:\n",
    "            _, T, _ = x.size()\n",
    "            length_list.append(T)\n",
    "\n",
    "        # Decompose to obtain the season and trend\n",
    "        season_list = []\n",
    "        trend_list = []\n",
    "        for x in x_list:\n",
    "            season, trend = self.decompsition(x)\n",
    "            if self.channel_independence == 0:\n",
    "                season = self.cross_layer(season)\n",
    "                trend = self.cross_layer(trend)\n",
    "            season_list.append(season.permute(0, 2, 1))\n",
    "            trend_list.append(trend.permute(0, 2, 1))\n",
    "\n",
    "        # bottom-up season mixing\n",
    "        out_season_list = self.mixing_multi_scale_season(season_list)\n",
    "        # top-down trend mixing\n",
    "        out_trend_list = self.mixing_multi_scale_trend(trend_list)\n",
    "\n",
    "        out_list = []\n",
    "        for ori, out_season, out_trend, length in zip(x_list, out_season_list, out_trend_list,\n",
    "                                                      length_list):\n",
    "            out = out_season + out_trend\n",
    "            if self.channel_independence:\n",
    "                out = ori + self.out_cross_layer(out)\n",
    "            out_list.append(out[:, :length, :])\n",
    "        return out_list\n",
    "\n",
    "\n",
    "class ContinuousScalingEmbedding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ContinuousScalingEmbedding, self).__init__()\n",
    "        self.nub_features = 7\n",
    "        self.embedding_dim = 96\n",
    "        self.embedding_weights = nn.Parameter(torch.randn( self.nub_features,  self.embedding_dim))\n",
    "        self.transform = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        #print(input_data.shape)\n",
    "        _, sequence_length, _ = input_data.shape\n",
    "        transform = self.transform(input_data.float())\n",
    "        #print('transform', transform.shape)\n",
    "        #print('self.embedding_weights', self.embedding_weights.shape)\n",
    "\n",
    "        embedded_data = transform * self.embedding_weights[:sequence_length].unsqueeze(0)\n",
    "        return embedded_data  \n",
    "        \n",
    "class WindowCrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, window_size=2):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.window_size = window_size\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_length, embed_dim]\n",
    "        batch_size, seq_length, embed_dim = x.shape\n",
    "\n",
    "        # Pad the sequence for windowing\n",
    "        padding = self.window_size\n",
    "        x_padded = F.pad(x, (0, 0, padding, padding), \"constant\", 0)\n",
    "\n",
    "        # Generate Q, K, V matrices\n",
    "        queries = x.clone() #self.query(x)\n",
    "        keys = x_padded.clone() #self.key(x_padded)\n",
    "        values = self.value(x_padded)\n",
    "\n",
    "        # Create a window for each sequence position\n",
    "        all_windows = seq_length + 2 * padding\n",
    "        windows_start = torch.arange(all_windows - 2 * padding)\n",
    "        windows_end = windows_start + 2 * padding + 1\n",
    "        k = torch.stack([keys[:, start:end, :] for start, end in zip(windows_start, windows_end)], dim=1)\n",
    "        v = torch.stack([values[:, start:end, :] for start, end in zip(windows_start, windows_end)], dim=1)\n",
    "\n",
    "        # Calculate attention scores\n",
    "        scores = torch.einsum('bik,bijk->bij', queries, k) / (embed_dim ** 0.5)\n",
    "        attention = self.softmax(scores)\n",
    "\n",
    "        # Apply attention to get the output\n",
    "        attended = torch.einsum('bij,bijk->bik', attention, v)\n",
    "\n",
    "        return attended\n",
    "    \n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.down_sampling_window = configs.down_sampling_window\n",
    "        self.channel_independence = configs.channel_independence\n",
    "        self.pdm_blocks = nn.ModuleList([PastDecomposableMixing(configs)\n",
    "                                         for _ in range(configs.e_layers)])\n",
    "\n",
    "        self.preprocess = series_decomp(configs.moving_avg)\n",
    "        self.enc_in = configs.enc_in\n",
    "        self.use_future_temporal_feature = configs.use_future_temporal_feature\n",
    "\n",
    "        if self.channel_independence == 1:\n",
    "            self.enc_embedding = DataEmbedding_wo_pos(1, configs.d_model, configs.embed, configs.freq,\n",
    "                                                      configs.dropout)\n",
    "        else:\n",
    "            self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                                      configs.dropout)\n",
    "\n",
    "        self.layer = configs.e_layers\n",
    "\n",
    "        self.normalize_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                Normalize(self.configs.enc_in, affine=True, non_norm=True if configs.use_norm == 0 else False)\n",
    "                for i in range(configs.down_sampling_layers + 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            self.predict_layers = torch.nn.ModuleList(\n",
    "                [\n",
    "                    torch.nn.Linear(\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                        configs.pred_len,\n",
    "                    )\n",
    "                    for i in range(configs.down_sampling_layers + 1)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if self.channel_independence == 1:\n",
    "                self.projection_layer = nn.Linear(\n",
    "                    configs.d_model, 1, bias=True)\n",
    "            else:\n",
    "                self.projection_layer = nn.Linear(\n",
    "                    configs.d_model, configs.c_out, bias=True)\n",
    "\n",
    "                self.out_res_layers = torch.nn.ModuleList([\n",
    "                    torch.nn.Linear(\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                        configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                    )\n",
    "                    for i in range(configs.down_sampling_layers + 1)\n",
    "                ])\n",
    "\n",
    "                self.regression_layers = torch.nn.ModuleList(\n",
    "                    [\n",
    "                        torch.nn.Linear(\n",
    "                            configs.seq_len // (configs.down_sampling_window ** i),\n",
    "                            configs.pred_len,\n",
    "                        )\n",
    "                        for i in range(configs.down_sampling_layers + 1)\n",
    "                    ]\n",
    "                )\n",
    "        if self.task_name == 'imputation' or self.task_name == 'anomaly_detection':\n",
    "            if self.channel_independence == 1:\n",
    "                self.projection_layer = nn.Linear(\n",
    "                    configs.d_model, 1, bias=True)\n",
    "            else:\n",
    "                self.projection_layer = nn.Linear(\n",
    "                    configs.d_model, configs.c_out, bias=True)\n",
    "        if self.task_name == 'classification':\n",
    "            self.act = F.gelu\n",
    "            self.dropout = nn.Dropout(configs.dropout)\n",
    "            self.projection = nn.Linear(\n",
    "                configs.d_model * configs.seq_len, configs.num_class)\n",
    "        \n",
    "\n",
    "        #d_list = [384, 192, 96, 48, 24, 12, 6]\n",
    "        self.ContinuousScalingEmbedding = ContinuousScalingEmbedding(configs)\n",
    "        self.window_attention  = WindowCrossAttention(186, 5)\n",
    "        self.seq_embd = TModel(configs)\n",
    "        self.top_k = 5\n",
    "        self.description = 'The Electricity Transformer Temperature (ETT) is a crucial indicator in the electric power long-term deployment.'\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "          \n",
    "\n",
    "        \n",
    "        #config.hidden_size = configs.d_model\n",
    "        #config.intermediate_size = configs.d_ff\n",
    "        pretrained_model = RobertaModel.from_pretrained('FacebookAI/roberta-base')\n",
    "\n",
    "  \n",
    "        \n",
    "        config = RobertaConfig(\n",
    "            hidden_size=16,  # Smaller hidden size\n",
    "            intermediate_size=32,  # Smaller intermediate layer size\n",
    "            num_attention_heads=2,  # Adjusted for smaller hidden size\n",
    "            num_hidden_layers=12,  # Keep the same number of layers\n",
    "        )\n",
    "        self.transformer = RobertaModel(config)\n",
    "        \n",
    "        # Transfer weights from the pretrained RoBERTa model to the custom model\n",
    "        for layer_idx in range(config.num_hidden_layers):\n",
    "            # Get the encoder layer\n",
    "            pretrained_layer = pretrained_model.encoder.layer[layer_idx]\n",
    "            custom_layer = self.transformer.encoder.layer[layer_idx]\n",
    "        \n",
    "            # Transfer attention weights (only the first 16 hidden dimensions)\n",
    "            custom_layer.attention.self.query.weight.data = pretrained_layer.attention.self.query.weight.data[:16, :16]\n",
    "            custom_layer.attention.self.query.bias.data = pretrained_layer.attention.self.query.bias.data[:16]\n",
    "        \n",
    "            custom_layer.attention.self.key.weight.data = pretrained_layer.attention.self.key.weight.data[:16, :16]\n",
    "            custom_layer.attention.self.key.bias.data = pretrained_layer.attention.self.key.bias.data[:16]\n",
    "        \n",
    "            custom_layer.attention.self.value.weight.data = pretrained_layer.attention.self.value.weight.data[:16, :16]\n",
    "            custom_layer.attention.self.value.bias.data = pretrained_layer.attention.self.value.bias.data[:16]\n",
    "        \n",
    "            # Transfer attention output projection weights (first 16 hidden dimensions)\n",
    "            custom_layer.attention.output.dense.weight.data = pretrained_layer.attention.output.dense.weight.data[:16, :16]\n",
    "            custom_layer.attention.output.dense.bias.data = pretrained_layer.attention.output.dense.bias.data[:16]\n",
    "        \n",
    "            # Transfer intermediate weights (first 16 from hidden to 32 in intermediate)\n",
    "            custom_layer.intermediate.dense.weight.data = pretrained_layer.intermediate.dense.weight.data[:32, :16]\n",
    "            custom_layer.intermediate.dense.bias.data = pretrained_layer.intermediate.dense.bias.data[:32]\n",
    "        \n",
    "            # Transfer output projection weights from intermediate (first 32 to 16)\n",
    "            custom_layer.output.dense.weight.data = pretrained_layer.output.dense.weight.data[:16, :32]\n",
    "            custom_layer.output.dense.bias.data = pretrained_layer.output.dense.bias.data[:16]\n",
    "        \n",
    "        # Now your custom RoBERTa model\n",
    "        \n",
    "        #self.transformer =  AutoModel.from_pretrained(\"FacebookAI/roberta-base\", config=config, ignore_mismatched_sizes=True)\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def out_projection(self, dec_out, i, out_res):\n",
    "        dec_out = self.projection_layer(dec_out)\n",
    "        out_res = out_res.permute(0, 2, 1)\n",
    "        out_res = self.out_res_layers[i](out_res)\n",
    "        out_res = self.regression_layers[i](out_res).permute(0, 2, 1)\n",
    "        dec_out = dec_out + out_res\n",
    "        return dec_out\n",
    "\n",
    "    def pre_enc(self, x_list):\n",
    "        if self.channel_independence == 1:\n",
    "            return (x_list, None)\n",
    "        else:\n",
    "            out1_list = []\n",
    "            out2_list = []\n",
    "            for x in x_list:\n",
    "                x_1, x_2 = self.preprocess(x)\n",
    "                out1_list.append(x_1)\n",
    "                out2_list.append(x_2)\n",
    "            return (out1_list, out2_list)\n",
    "\n",
    "    def __multi_scale_process_inputs(self, x_enc, x_mark_enc):\n",
    "        if self.configs.down_sampling_method == 'max':\n",
    "            down_pool = torch.nn.MaxPool1d(self.configs.down_sampling_window, return_indices=False)\n",
    "        elif self.configs.down_sampling_method == 'avg':\n",
    "            down_pool = torch.nn.AvgPool1d(self.configs.down_sampling_window)\n",
    "        elif self.configs.down_sampling_method == 'conv':\n",
    "            padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "            down_pool = nn.Conv1d(in_channels=self.configs.enc_in, out_channels=self.configs.enc_in,\n",
    "                                  kernel_size=5, padding=padding,\n",
    "                                  stride=self.configs.down_sampling_window,\n",
    "                                  padding_mode='circular',\n",
    "                                  bias=False)\n",
    "        else:\n",
    "            return x_enc, x_mark_enc\n",
    "        # B,T,C -> B,C,T\n",
    "        x_enc = x_enc.permute(0, 2, 1)\n",
    "\n",
    "        x_enc_ori = x_enc\n",
    "        x_mark_enc_mark_ori = x_mark_enc\n",
    "\n",
    "        x_enc_sampling_list = []\n",
    "        x_mark_sampling_list = []\n",
    "        x_enc_sampling_list.append(x_enc.permute(0, 2, 1))\n",
    "        x_mark_sampling_list.append(x_mark_enc)\n",
    "\n",
    "        for i in range(self.configs.down_sampling_layers):\n",
    "            x_enc_sampling = down_pool(x_enc_ori)\n",
    "\n",
    "            x_enc_sampling_list.append(x_enc_sampling.permute(0, 2, 1))\n",
    "            x_enc_ori = x_enc_sampling\n",
    "\n",
    "            if x_mark_enc_mark_ori is not None:\n",
    "                x_mark_sampling_list.append(x_mark_enc_mark_ori[:, ::self.configs.down_sampling_window, :])\n",
    "                x_mark_enc_mark_ori = x_mark_enc_mark_ori[:, ::self.configs.down_sampling_window, :]\n",
    "\n",
    "        x_enc = x_enc_sampling_list\n",
    "        if x_mark_enc_mark_ori is not None:\n",
    "            x_mark_enc = x_mark_sampling_list\n",
    "        else:\n",
    "            x_mark_enc = x_mark_enc\n",
    "\n",
    "        return x_enc, x_mark_enc\n",
    "\n",
    "    def calcute_lags(self, x_enc):\n",
    "        q_fft = torch.fft.rfft(x_enc.permute(0, 2, 1).contiguous(), dim=-1)\n",
    "        k_fft = torch.fft.rfft(x_enc.permute(0, 2, 1).contiguous(), dim=-1)\n",
    "        res = q_fft * torch.conj(k_fft)\n",
    "        corr = torch.fft.irfft(res, dim=-1)\n",
    "        mean_value = torch.mean(corr, dim=1)\n",
    "        _, lags = torch.topk(mean_value, self.top_k, dim=-1)\n",
    "        return lags\n",
    "    \n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        #print('x_enc',x_enc.shape)\n",
    "\n",
    "        #x_enc = self.ContinuousScalingEmbedding(x_enc.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        B, T, N = x_enc.size()\n",
    "        x_enc = x_enc.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "\n",
    "        min_values = torch.min(x_enc, dim=1)[0]\n",
    "        max_values = torch.max(x_enc, dim=1)[0]\n",
    "        medians = torch.median(x_enc, dim=1).values\n",
    "        lags = self.calcute_lags(x_enc)\n",
    "        trends = x_enc.diff(dim=1).sum(dim=1)\n",
    "\n",
    "        \n",
    "\n",
    "        prompt = []\n",
    "        for b in range(x_enc.shape[0]):\n",
    "            min_values_str = str(min_values[b].tolist()[0])\n",
    "            max_values_str = str(max_values[b].tolist()[0])\n",
    "            median_values_str = str(medians[b].tolist()[0])\n",
    "            lags_values_str = str(lags[b].tolist())\n",
    "            prompt_ = (\n",
    "                f\"<|start_prompt|>Dataset description: {self.description}\"\n",
    "                f\"Task description: forecast the next {str(self.pred_len)} steps given the previous {str(self.seq_len)} steps information; \"\n",
    "                \"Input statistics: \"\n",
    "                f\"min value {min_values_str}, \"\n",
    "                f\"max value {max_values_str}, \"\n",
    "                f\"median value {median_values_str}, \"\n",
    "                f\"the trend of input is {'upward' if trends[b] > 0 else 'downward'}, \"\n",
    "                f\"top 5 lags are : {lags_values_str}<|<end_prompt>|>\"\n",
    "            )\n",
    "\n",
    "            prompt.append(prompt_)\n",
    "        #print('tab_embedding_res',tab_embedding_res.shape)\n",
    "        x_enc = x_enc.reshape(B, N, T).permute(0, 2, 1).contiguous()\n",
    "\n",
    "        prompt = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).input_ids\n",
    "        prompt_embeddings = self.transformer.get_input_embeddings()(prompt.to(x_enc.device))  # (batch, prompt_token, dim)\n",
    "\n",
    "        #print('prompt_embeddings', prompt_embeddings.shape)\n",
    "\n",
    "        if self.use_future_temporal_feature:\n",
    "            if self.channel_independence == 1:\n",
    "                B, T, N = x_enc.size()\n",
    "                x_mark_dec = x_mark_dec.repeat(N, 1, 1)\n",
    "                self.x_mark_dec = self.enc_embedding(None, x_mark_dec)\n",
    "            else:\n",
    "                self.x_mark_dec = self.enc_embedding(None, x_mark_dec)\n",
    "\n",
    "        x_enc, x_mark_enc = self.__multi_scale_process_inputs(x_enc, x_mark_enc)\n",
    "        #print(type(x_enc), 'x_enc')\n",
    "\n",
    "        x_list = []\n",
    "        x_mark_list = []\n",
    "        if x_mark_enc is not None:\n",
    "            for i, x, x_mark in zip(range(len(x_enc)), x_enc, x_mark_enc):\n",
    "                B, T, N = x.size()\n",
    "                x = self.normalize_layers[i](x, 'norm')\n",
    "                if self.channel_independence == 1:\n",
    "                    x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "                    x_mark = x_mark.repeat(N, 1, 1)\n",
    "                x_list.append(x)\n",
    "                x_mark_list.append(x_mark)\n",
    "        else:\n",
    "            for i, x in zip(range(len(x_enc)), x_enc, ):\n",
    "                B, T, N = x.size()\n",
    "                x = self.normalize_layers[i](x, 'norm')\n",
    "                if self.channel_independence == 1:\n",
    "                    x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "                x_list.append(x)\n",
    "\n",
    "        # embedding\n",
    "        enc_out_list = []\n",
    "        x_list = self.pre_enc(x_list)\n",
    "        if x_mark_enc is not None:\n",
    "            for i, x, x_mark in zip(range(len(x_list[0])), x_list[0], x_mark_list):\n",
    "                enc_out = self.enc_embedding(x, x_mark)  # [B,T,C]\n",
    "                enc_out_list.append(enc_out)\n",
    "        else:\n",
    "            for i, x in zip(range(len(x_list[0])), x_list[0]):\n",
    "                enc_out = self.enc_embedding(x, None)  # [B,T,C]\n",
    "                enc_out_list.append(enc_out)\n",
    "        #print(len(enc_out_list), enc_out_list[0].shape, enc_out_list[1].shape, enc_out_list[2].shape, enc_out_list[3].shape)\n",
    "        # Past Decomposable Mixing as encoder for past\n",
    "\n",
    "        for i in range(self.layer):\n",
    "            enc_out_list = self.pdm_blocks[i](enc_out_list)\n",
    "        inputs_embeds = torch.cat(enc_out_list, dim=1)#.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "        inputs_embeds = torch.cat([prompt_embeddings, inputs_embeds], dim=1)\n",
    "\n",
    "        \n",
    "        #print('inputs_embeds', inputs_embeds.shape, prompt_embeddings.shape)\n",
    "        #inputs_embeds = self.window_attention(inputs_embeds)\n",
    "        \n",
    "        #old_pad = inputs_embeds.shape[2]\n",
    "        #inputs_embeds  = F.pad(inputs_embeds, (0, 768 - old_pad))\n",
    "        #inputs_embeds, attns = self.encoder(inputs_embeds, attn_mask=None)\n",
    "        #inputs_embeds = torch.cat([prompt_embeddings, inputs_embeds], dim=1)\n",
    "        #print('inputs_embeds', inputs_embeds.shape)\n",
    "        \n",
    "        outputs = self.transformer(\n",
    "                    inputs_embeds=inputs_embeds)\n",
    "\n",
    "\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        \n",
    "\n",
    "        #print('hidden_states', hidden_states.shape)\n",
    "       \n",
    "\n",
    "        #hidden_states = hidden_states[:, prompt_embeddings.shape[1]:, :]#.permute(0, 2, 1)\n",
    "        #print(hidden_states.shape)\n",
    "        #hidden_states = self.merge(hidden_states).permute(0, 2, 1)\n",
    "\n",
    "        #print('hidden_states', hidden_states.shape)\n",
    "        #print('inputs_embeds', hidden_states.shape)\n",
    "\n",
    "        split_sizes = [tensor.size(1) for tensor in enc_out_list]  # Get the sizes of each tensor along dimension 1\n",
    "        enc_out_list  = list(torch.split(hidden_states, split_sizes, dim=1))  # Convert tuple to list\n",
    "\n",
    "        # Future Multipredictor Mixing as decoder for future\n",
    "        dec_out_list = self.future_multi_mixing(B, enc_out_list, x_list)\n",
    "\n",
    "        dec_out = torch.stack(dec_out_list, dim=-1).sum(-1)\n",
    "\n",
    "        #dec_out = self.decoder(dec_out)\n",
    "\n",
    "\n",
    "        #dec_out  = self.seq_embd(dec_out)\n",
    "        dec_out = self.normalize_layers[0](dec_out, 'denorm')\n",
    "        \n",
    "        return dec_out\n",
    "\n",
    "    def future_multi_mixing(self, B, enc_out_list, x_list):\n",
    "        dec_out_list = []\n",
    "        if self.channel_independence == 1:\n",
    "            x_list = x_list[0]\n",
    "            for i, enc_out in zip(range(len(x_list)), enc_out_list):\n",
    "                dec_out = self.predict_layers[i](enc_out.permute(0, 2, 1)).permute(\n",
    "                    0, 2, 1)  # align temporal dimension\n",
    "                if self.use_future_temporal_feature:\n",
    "                    dec_out = dec_out + self.x_mark_dec\n",
    "                    dec_out = self.projection_layer(dec_out)\n",
    "                else:\n",
    "                    dec_out = self.projection_layer(dec_out)\n",
    "                dec_out = dec_out.reshape(B, self.configs.c_out, self.pred_len).permute(0, 2, 1).contiguous()\n",
    "                dec_out_list.append(dec_out)\n",
    "\n",
    "        else:\n",
    "            for i, enc_out, out_res in zip(range(len(x_list[0])), enc_out_list, x_list[1]):\n",
    "                dec_out = self.predict_layers[i](enc_out.permute(0, 2, 1)).permute(\n",
    "                    0, 2, 1)  # align temporal dimension\n",
    "                dec_out = self.out_projection(dec_out, i, out_res)\n",
    "                dec_out_list.append(dec_out)\n",
    "\n",
    "        return dec_out_list\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        x_enc, _ = self.__multi_scale_process_inputs(x_enc, None)\n",
    "        x_list = x_enc\n",
    "\n",
    "        # embedding\n",
    "        enc_out_list = []\n",
    "        for x in x_list:\n",
    "            enc_out = self.enc_embedding(x, None)  # [B,T,C]\n",
    "            enc_out_list.append(enc_out)\n",
    "\n",
    "        # MultiScale-CrissCrossAttention  as encoder for past\n",
    "        for i in range(self.layer):\n",
    "            enc_out_list = self.pdm_blocks[i](enc_out_list)\n",
    "\n",
    "        enc_out = enc_out_list[0]\n",
    "        # Output\n",
    "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        # zero-out padding embeddings\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        # (batch_size, seq_length * d_model)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)  # (batch_size, num_classes)\n",
    "        return output\n",
    "\n",
    "    def anomaly_detection(self, x_enc):\n",
    "        B, T, N = x_enc.size()\n",
    "        x_enc, _ = self.__multi_scale_process_inputs(x_enc, None)\n",
    "\n",
    "        x_list = []\n",
    "\n",
    "        for i, x in zip(range(len(x_enc)), x_enc, ):\n",
    "            B, T, N = x.size()\n",
    "            x = self.normalize_layers[i](x, 'norm')\n",
    "            if self.channel_independence == 1:\n",
    "                x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "            x_list.append(x)\n",
    "\n",
    "        # embedding\n",
    "        enc_out_list = []\n",
    "        for x in x_list:\n",
    "            enc_out = self.enc_embedding(x, None)  # [B,T,C]\n",
    "            enc_out_list.append(enc_out)\n",
    "\n",
    "        # MultiScale-CrissCrossAttention  as encoder for past\n",
    "        for i in range(self.layer):\n",
    "            enc_out_list = self.pdm_blocks[i](enc_out_list)\n",
    "\n",
    "        dec_out = self.projection_layer(enc_out_list[0])\n",
    "        dec_out = dec_out.reshape(B, self.configs.c_out, -1).permute(0, 2, 1).contiguous()\n",
    "\n",
    "        dec_out = self.normalize_layers[0](dec_out, 'denorm')\n",
    "        return dec_out\n",
    "\n",
    "    def imputation(self, x_enc, x_mark_enc, mask):\n",
    "        means = torch.sum(x_enc, dim=1) / torch.sum(mask == 1, dim=1)\n",
    "        means = means.unsqueeze(1).detach()\n",
    "        x_enc = x_enc - means\n",
    "        x_enc = x_enc.masked_fill(mask == 0, 0)\n",
    "        stdev = torch.sqrt(torch.sum(x_enc * x_enc, dim=1) /\n",
    "                           torch.sum(mask == 1, dim=1) + 1e-5)\n",
    "        stdev = stdev.unsqueeze(1).detach()\n",
    "        x_enc /= stdev\n",
    "\n",
    "        B, T, N = x_enc.size()\n",
    "        x_enc, x_mark_enc = self.__multi_scale_process_inputs(x_enc, x_mark_enc)\n",
    "\n",
    "        x_list = []\n",
    "        x_mark_list = []\n",
    "        if x_mark_enc is not None:\n",
    "            for i, x, x_mark in zip(range(len(x_enc)), x_enc, x_mark_enc):\n",
    "                B, T, N = x.size()\n",
    "                if self.channel_independence == 1:\n",
    "                    x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "                x_list.append(x)\n",
    "                x_mark = x_mark.repeat(N, 1, 1)\n",
    "                x_mark_list.append(x_mark)\n",
    "        else:\n",
    "            for i, x in zip(range(len(x_enc)), x_enc, ):\n",
    "                B, T, N = x.size()\n",
    "                if self.channel_independence == 1:\n",
    "                    x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "                x_list.append(x)\n",
    "\n",
    "        # embedding\n",
    "        enc_out_list = []\n",
    "        for x in x_list:\n",
    "            enc_out = self.enc_embedding(x, None)  # [B,T,C]\n",
    "            enc_out_list.append(enc_out)\n",
    "\n",
    "        # MultiScale-CrissCrossAttention  as encoder for past\n",
    "        for i in range(self.layer):\n",
    "            enc_out_list = self.pdm_blocks[i](enc_out_list)\n",
    "\n",
    "        dec_out = self.projection_layer(enc_out_list[0])\n",
    "        dec_out = dec_out.reshape(B, self.configs.c_out, -1).permute(0, 2, 1).contiguous()\n",
    "\n",
    "        dec_out = dec_out * \\\n",
    "                  (stdev[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n",
    "        dec_out = dec_out + \\\n",
    "                  (means[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n",
    "        return dec_out\n",
    "\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "            return dec_out\n",
    "        if self.task_name == 'imputation':\n",
    "            dec_out = self.imputation(x_enc, x_mark_enc, mask)\n",
    "            return dec_out  # [B, L, D]\n",
    "        if self.task_name == 'anomaly_detection':\n",
    "            dec_out = self.anomaly_detection(x_enc)\n",
    "            return dec_out  # [B, L, D]\n",
    "        if self.task_name == 'classification':\n",
    "            dec_out = self.classification(x_enc, x_mark_enc)\n",
    "            return dec_out  # [B, N]\n",
    "        else:\n",
    "            raise ValueError('Other tasks implemented yet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
